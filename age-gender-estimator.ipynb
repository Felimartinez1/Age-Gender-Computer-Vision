{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-26T17:47:44.208502Z","iopub.execute_input":"2023-09-26T17:47:44.208893Z","iopub.status.idle":"2023-09-26T17:47:44.242630Z","shell.execute_reply.started":"2023-09-26T17:47:44.208862Z","shell.execute_reply":"2023-09-26T17:47:44.241388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install seaborn\n!pip install Pillow\n!pip install imgaug","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:11:34.067806Z","iopub.execute_input":"2023-09-28T00:11:34.068788Z","iopub.status.idle":"2023-09-28T00:11:52.285499Z","shell.execute_reply.started":"2023-09-28T00:11:34.068745Z","shell.execute_reply":"2023-09-28T00:11:52.284237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array  # Importa img_to_array de Keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport random\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport cv2\nimport imgaug.augmenters as iaa\n\nimport os\nfrom tqdm.notebook import tqdm\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:11:52.287775Z","iopub.execute_input":"2023-09-28T00:11:52.288223Z","iopub.status.idle":"2023-09-28T00:12:35.763684Z","shell.execute_reply.started":"2023-09-28T00:11:52.288187Z","shell.execute_reply":"2023-09-28T00:12:35.762687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configura la estrategia de la TPU\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.TPUStrategy(resolver)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:35.764917Z","iopub.execute_input":"2023-09-28T00:12:35.765621Z","iopub.status.idle":"2023-09-28T00:12:43.475063Z","shell.execute_reply.started":"2023-09-28T00:12:35.765589Z","shell.execute_reply":"2023-09-28T00:12:43.474118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/utkface-new/UTKFace'\nage_labels = []\ngender_labels = []\nimage_paths = []\n\nimage_filenames = os.listdir(path)\nrandom.shuffle(image_filenames)\n\nfor image in image_filenames:\n    image_path = os.path.join(path, image)\n    img_components = image.split('_')\n    age_label = int(img_components[0])\n    gender_label = int(img_components[1])\n    \n    age_labels.append(age_label)\n    gender_labels.append(gender_label)\n    image_paths.append(image_path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:43.477265Z","iopub.execute_input":"2023-09-28T00:12:43.477563Z","iopub.status.idle":"2023-09-28T00:12:43.860287Z","shell.execute_reply.started":"2023-09-28T00:12:43.477538Z","shell.execute_reply":"2023-09-28T00:12:43.859285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of age_labels: {len(age_labels)}, Number of gender_labels: {len(gender_labels)}, Number of image_paths: {len(image_paths)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:43.861359Z","iopub.execute_input":"2023-09-28T00:12:43.861634Z","iopub.status.idle":"2023-09-28T00:12:43.866337Z","shell.execute_reply.started":"2023-09-28T00:12:43.861610Z","shell.execute_reply":"2023-09-28T00:12:43.865393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(age_labels[:10])\nprint(gender_labels[:10])\nprint(image_paths[:10])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:43.867462Z","iopub.execute_input":"2023-09-28T00:12:43.867804Z","iopub.status.idle":"2023-09-28T00:12:43.875650Z","shell.execute_reply.started":"2023-09-28T00:12:43.867770Z","shell.execute_reply":"2023-09-28T00:12:43.874737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['image_path'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:43.876662Z","iopub.execute_input":"2023-09-28T00:12:43.877042Z","iopub.status.idle":"2023-09-28T00:12:43.921844Z","shell.execute_reply.started":"2023-09-28T00:12:43.877015Z","shell.execute_reply":"2023-09-28T00:12:43.921061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" sns.distplot(df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:43.922877Z","iopub.execute_input":"2023-09-28T00:12:43.923162Z","iopub.status.idle":"2023-09-28T00:12:44.449186Z","shell.execute_reply.started":"2023-09-28T00:12:43.923138Z","shell.execute_reply":"2023-09-28T00:12:44.448076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=df, x='gender')\n\n# Añade etiquetas y título al gráfico\nplt.xlabel('Gender')\nplt.ylabel('Quantity')\nplt.title('Gender Distribution')\n\n# Muestra el gráfico\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:12:44.450427Z","iopub.execute_input":"2023-09-28T00:12:44.450719Z","iopub.status.idle":"2023-09-28T00:12:44.629430Z","shell.execute_reply.started":"2023-09-28T00:12:44.450693Z","shell.execute_reply":"2023-09-28T00:12:44.628228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_data_augmentation(image_path):\n    # Carga la imagen\n    img = load_img(image_path)\n    img = img_to_array(img)\n    \n    # Define una secuencia de aumentos de datos\n    seq = iaa.Sequential([\n        iaa.Affine(rotate=(-10, 10)),  # Rotación en un rango de -10 a 10 grados\n        iaa.Fliplr(0.9),  # Volteo horizontal con probabilidad del 90%\n        iaa.Sometimes(0.7, iaa.GaussianBlur(sigma=(0, 2.0))),  # Aplicar desenfoque gaussiano con probabilidad del 70%\n        iaa.Sometimes(0.6, iaa.AdditiveGaussianNoise(scale=(0, 0.05 * 255))),  # Agregar ruido gaussiano con probabilidad del 60%\n        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),  # Ajustar el contraste\n    ])\n    \n    # Aplica las transformaciones\n    augmented_img = seq(image=img)\n    return augmented_img\n\n# Selecciona las imágenes de edades entre 5 a 20 años y de 40 a 90 años\nselected_images = df[(df['age'] >= 5) & (df['age'] <= 20) | (df['age'] >= 40) & (df['age'] <= 90)]\n\n# Aplica aumentos de datos a las imágenes seleccionadas\naugmented_images = []\nfor image_path in selected_images['image_path']:\n    augmented_img = apply_data_augmentation(image_path)\n    augmented_images.append(augmented_img)\n\n# Crear una nueva lista de rutas de imagen para las imágenes aumentadas\naugmented_image_paths = []\n\n# Crear una nueva lista de edades y géneros para las imágenes aumentadas\naugmented_age_labels = []\naugmented_gender_labels = []\n\n# Directorio donde guardar las imágenes aumentadas\n\n############\noutput_directory = '/kaggle/working/augmented_images'  ##### Cambia esto a la ubicación deseada\nos.makedirs(output_directory, exist_ok=True)\n############\n\n# Iterar a través de las imágenes originales y sus correspondientes imágenes aumentadas\nfor image_path, age_label, gender_label, augmented_img in zip(selected_images['image_path'], selected_images['age'], selected_images['gender'], augmented_images):\n    # Generar una nueva ruta de imagen para la imagen aumentada\n    augmented_image_filename = os.path.basename(image_path).replace('.jpg', '_augmented.jpg')\n    augmented_image_path = os.path.join(output_directory, augmented_image_filename)\n    \n    # Guardar la ruta de imagen aumentada en la lista\n    augmented_image_paths.append(augmented_image_path)\n    \n    # Guardar la misma edad y género para la imagen aumentada\n    augmented_age_labels.append(age_label)\n    augmented_gender_labels.append(gender_label)\n    \n    # Guardar la imagen aumentada en el sistema de archivos\n    plt.imsave(augmented_image_path, augmented_img.astype(np.uint8))\n\n# Verifica el número total de imágenes originales y aumentadas\nprint(f\"Número de imágenes originales: {len(selected_images)}\")\nprint(f\"Número de imágenes aumentadas: {len(augmented_images)}\")\n\n# Crear un nuevo DataFrame con las imágenes aumentadas y sus etiquetas\naugmented_df = pd.DataFrame()\naugmented_df['image_path'] = augmented_image_paths\naugmented_df['age'] = augmented_age_labels\naugmented_df['gender'] = augmented_gender_labels\n\n# Verifica el número total de filas en el DataFrame combinado\nprint(f\"Número total de filas en combined_df: {len(combined_df)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T00:52:52.070667Z","iopub.execute_input":"2023-09-28T00:52:52.071122Z","iopub.status.idle":"2023-09-28T00:54:19.432121Z","shell.execute_reply.started":"2023-09-28T00:52:52.071067Z","shell.execute_reply":"2023-09-28T00:54:19.431075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df = pd.concat([df, augmented_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:18:16.459740Z","iopub.execute_input":"2023-09-28T01:18:16.460428Z","iopub.status.idle":"2023-09-28T01:18:16.466608Z","shell.execute_reply.started":"2023-09-28T01:18:16.460393Z","shell.execute_reply":"2023-09-28T01:18:16.465450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:18:26.823983Z","iopub.execute_input":"2023-09-28T01:18:26.824560Z","iopub.status.idle":"2023-09-28T01:18:26.837509Z","shell.execute_reply.started":"2023-09-28T01:18:26.824528Z","shell.execute_reply":"2023-09-28T01:18:26.836448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**BEFORE**","metadata":{}},{"cell_type":"code","source":"sns.distplot(df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:22:54.319483Z","iopub.execute_input":"2023-09-28T01:22:54.320594Z","iopub.status.idle":"2023-09-28T01:22:54.861394Z","shell.execute_reply.started":"2023-09-28T01:22:54.320542Z","shell.execute_reply":"2023-09-28T01:22:54.860090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AFTER**","metadata":{}},{"cell_type":"code","source":"sns.distplot(combined_df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:22:54.863162Z","iopub.execute_input":"2023-09-28T01:22:54.863467Z","iopub.status.idle":"2023-09-28T01:22:55.416998Z","shell.execute_reply.started":"2023-09-28T01:22:54.863439Z","shell.execute_reply":"2023-09-28T01:22:55.415788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualiza una imagen original y su versión aumentada\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.title(\"Imagen Original\")\nimg = load_img(selected_images.iloc[3]['image_path'])\nplt.imshow(img)\nplt.subplot(1, 2, 2)\nplt.title(\"Imagen Aumentada\")\naugmented_img = augmented_images[3]\naugmented_img = np.clip(augmented_img, 0, 255).astype(np.uint8)  # Normaliza los valores de píxeles\nplt.imshow(augmented_img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:26:06.579105Z","iopub.execute_input":"2023-09-28T01:26:06.580198Z","iopub.status.idle":"2023-09-28T01:26:07.129351Z","shell.execute_reply.started":"2023-09-28T01:26:06.580153Z","shell.execute_reply":"2023-09-28T01:26:07.127941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(augmented_images)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:00:00.725093Z","iopub.execute_input":"2023-09-28T01:00:00.725513Z","iopub.status.idle":"2023-09-28T01:00:00.732158Z","shell.execute_reply.started":"2023-09-28T01:00:00.725480Z","shell.execute_reply":"2023-09-28T01:00:00.731113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_image_features(images):\n    features = list()\n\n    for image in images:\n        img = load_img(image, grayscale=True)\n        img = img.resize((128, 128), Image.LANCZOS)\n        img = np.array(img)\n        features.append(img)\n\n    features = np.array(features)\n    features = features.reshape(len(features), 128, 128, 1)\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-09-28T01:30:54.667117Z","iopub.execute_input":"2023-09-28T01:30:54.667595Z","iopub.status.idle":"2023-09-28T01:30:54.675291Z","shell.execute_reply.started":"2023-09-28T01:30:54.667559Z","shell.execute_reply":"2023-09-28T01:30:54.674250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtra el DataFrame para obtener solo las imágenes con edad menor a 90\nfiltered_df = combined_df[combined_df['age'] < 60]\n\n# Extrae las características de las imágenes\nX = extract_image_features(filtered_df['image_path'])\n\n# Normaliza las características\nX = X / 255.0\n\n# Verifica la forma de X\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T02:06:05.402661Z","iopub.execute_input":"2023-09-28T02:06:05.403571Z","iopub.status.idle":"2023-09-28T02:06:51.704445Z","shell.execute_reply.started":"2023-09-28T02:06:05.403530Z","shell.execute_reply":"2023-09-28T02:06:51.702944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_gender = np.array(filtered_df['gender'])\ny_age = np.array(filtered_df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T02:06:51.706221Z","iopub.execute_input":"2023-09-28T02:06:51.706561Z","iopub.status.idle":"2023-09-28T02:06:51.711962Z","shell.execute_reply.started":"2023-09-28T02:06:51.706533Z","shell.execute_reply":"2023-09-28T02:06:51.710914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Duplica el canal de imágenes en escala de grises para convertirlas en imágenes RGB\nX_rgb = np.repeat(X, 3, axis=-1)\n\n# Asegúrate de que las imágenes estén en el rango [0, 255]\nX_rgb = X_rgb * 255\n\n# Redimensiona tus imágenes a 224x224\ndef resize_images(images):\n    resized_images = []\n    for image in images:\n        img = cv2.resize(image, (224, 224))\n        resized_images.append(img)\n    return np.array(resized_images)\n\nX_rgb = resize_images(X_rgb)\n\n# Asegúrate de que las imágenes estén en el rango [0, 1]\nX_rgb = X_rgb / 255.0\n\n# Divide tus datos en conjuntos de entrenamiento y prueba\nX_train, X_test, y_gender_train, y_gender_test, y_age_train, y_age_test = train_test_split(X_rgb, y_gender, y_age, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T02:06:51.713199Z","iopub.execute_input":"2023-09-28T02:06:51.713527Z","iopub.status.idle":"2023-09-28T02:08:11.368052Z","shell.execute_reply.started":"2023-09-28T02:06:51.713498Z","shell.execute_reply":"2023-09-28T02:08:11.366457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definir la entrada de la red\ninput_shape = (224, 224, 3)\n\nwith strategy.scope():\n    inputs = Input(shape=input_shape)\n\n    # Capas de convolución y max-pooling\n    conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n    max_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n    conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(max_1)\n    max_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n    conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu')(max_2)\n    max_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\n    conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu')(max_3)\n    max_4 = MaxPooling2D(pool_size=(2, 2))(conv_4)\n\n    # Capas de aplanamiento y completamente conectadas\n    flatten = Flatten()(max_4)\n    dense_1 = Dense(256, activation='relu')(flatten)\n    dropout_1 = Dropout(0.3)(dense_1)\n\n    # Capa de salida para la predicción de género\n    output_gender = Dense(1, activation='sigmoid', name='gender_out')(dropout_1)\n\n    # Crear el modelo\n    gender_model = Model(inputs=inputs, outputs=output_gender)\n\n    # Compilar el modelo solo para la predicción de género\n    gender_model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n\n    # URL del modelo preentrenado de ResNet\n    resnet_model_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n\n    # Cargar el modelo preentrenado\n    resnet_feature_extractor = hub.KerasLayer(resnet_model_url, input_shape=(224, 224, 3))\n\n    # Crear el modelo personalizado\n    age_model = tf.keras.Sequential([\n        resnet_feature_extractor,\n        Dense(256, activation='relu'),\n        Dropout(0.3),\n        Dense(1, activation='linear', name='age_out')\n    ])\n\n    age_model.compile(loss='mean_absolute_error',\n                      optimizer='RMSprop',\n                      metrics=['mae'])\n\n    # Entrena ambos modelos por separado\n    gender_model.fit(X_train, y_gender_train, epochs=17, batch_size=32, validation_split=0.2)\n    age_model.fit(X_train, y_age_train, epochs=20, batch_size=32, validation_split=0.2)\n\n    # Evalúa ambos modelos\n    gender_loss, gender_accuracy = gender_model.evaluate(X_test, y_gender_test)\n    age_loss, age_mae = age_model.evaluate(X_test, y_age_test)\n\nprint(\"Gender Model - Loss:\", gender_loss, \"Accuracy:\", gender_accuracy)\nprint(\"Age Model - Loss:\", age_loss, \"MAE:\", age_mae)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T02:09:44.524902Z","iopub.execute_input":"2023-09-28T02:09:44.525413Z","iopub.status.idle":"2023-09-28T02:21:57.629858Z","shell.execute_reply.started":"2023-09-28T02:09:44.525363Z","shell.execute_reply":"2023-09-28T02:21:57.628489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}