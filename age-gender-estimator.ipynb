{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-26T17:47:44.208502Z","iopub.execute_input":"2023-09-26T17:47:44.208893Z","iopub.status.idle":"2023-09-26T17:47:44.242630Z","shell.execute_reply.started":"2023-09-26T17:47:44.208862Z","shell.execute_reply":"2023-09-26T17:47:44.241388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install seaborn\n!pip install Pillow\n!pip install imgaug\n!pip install opencv-python\n!apt-get update\n!apt-get install -y libgl1-mesa-glx","metadata":{"execution":{"iopub.status.busy":"2023-09-28T15:57:27.961267Z","iopub.execute_input":"2023-09-28T15:57:27.961811Z","iopub.status.idle":"2023-09-28T15:57:59.157102Z","shell.execute_reply.started":"2023-09-28T15:57:27.961770Z","shell.execute_reply":"2023-09-28T15:57:59.155938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import img_to_array  # Importa img_to_array de Keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport random\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport cv2\nimport imgaug.augmenters as iaa\n\nimport os\nfrom tqdm.notebook import tqdm\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:11:56.771683Z","iopub.execute_input":"2023-09-28T16:11:56.772573Z","iopub.status.idle":"2023-09-28T16:11:56.785374Z","shell.execute_reply.started":"2023-09-28T16:11:56.772519Z","shell.execute_reply":"2023-09-28T16:11:56.784477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configura la estrategia de la TPU\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.TPUStrategy(resolver)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:11:59.675079Z","iopub.execute_input":"2023-09-28T16:11:59.675479Z","iopub.status.idle":"2023-09-28T16:12:08.148994Z","shell.execute_reply.started":"2023-09-28T16:11:59.675448Z","shell.execute_reply":"2023-09-28T16:12:08.148071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/utkface-new/UTKFace'\nage_labels = []\ngender_labels = []\nimage_paths = []\n\nimage_filenames = os.listdir(path)\nrandom.shuffle(image_filenames)\n\nfor image in image_filenames:\n    image_path = os.path.join(path, image)\n    img_components = image.split('_')\n    age_label = int(img_components[0])\n    gender_label = int(img_components[1])\n    \n    age_labels.append(age_label)\n    gender_labels.append(gender_label)\n    image_paths.append(image_path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:08.150482Z","iopub.execute_input":"2023-09-28T16:12:08.150778Z","iopub.status.idle":"2023-09-28T16:12:10.525903Z","shell.execute_reply.started":"2023-09-28T16:12:08.150753Z","shell.execute_reply":"2023-09-28T16:12:10.524788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of age_labels: {len(age_labels)}, Number of gender_labels: {len(gender_labels)}, Number of image_paths: {len(image_paths)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:10.527198Z","iopub.execute_input":"2023-09-28T16:12:10.527525Z","iopub.status.idle":"2023-09-28T16:12:10.532844Z","shell.execute_reply.started":"2023-09-28T16:12:10.527497Z","shell.execute_reply":"2023-09-28T16:12:10.531794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(age_labels[:10])\nprint(gender_labels[:10])\nprint(image_paths[:10])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:10.535038Z","iopub.execute_input":"2023-09-28T16:12:10.535321Z","iopub.status.idle":"2023-09-28T16:12:10.550390Z","shell.execute_reply.started":"2023-09-28T16:12:10.535297Z","shell.execute_reply":"2023-09-28T16:12:10.549456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['image_path'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:10.551544Z","iopub.execute_input":"2023-09-28T16:12:10.551881Z","iopub.status.idle":"2023-09-28T16:12:10.607513Z","shell.execute_reply.started":"2023-09-28T16:12:10.551853Z","shell.execute_reply":"2023-09-28T16:12:10.606391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" sns.distplot(df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:10.608873Z","iopub.execute_input":"2023-09-28T16:12:10.609219Z","iopub.status.idle":"2023-09-28T16:12:11.200047Z","shell.execute_reply.started":"2023-09-28T16:12:10.609190Z","shell.execute_reply":"2023-09-28T16:12:11.198853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=df, x='gender')\n\n# Añade etiquetas y título al gráfico\nplt.xlabel('Gender')\nplt.ylabel('Quantity')\nplt.title('Gender Distribution')\n\n# Muestra el gráfico\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:11.201221Z","iopub.execute_input":"2023-09-28T16:12:11.201499Z","iopub.status.idle":"2023-09-28T16:12:11.397856Z","shell.execute_reply.started":"2023-09-28T16:12:11.201475Z","shell.execute_reply":"2023-09-28T16:12:11.396392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_data_augmentation(image_path):\n    # Carga la imagen\n    img = load_img(image_path)\n    img = img_to_array(img)\n    \n    # Define una secuencia de aumentos de datos\n    seq = iaa.Sequential([\n        iaa.Affine(rotate=(-10, 10)),  # Rotación en un rango de -10 a 10 grados\n        iaa.Fliplr(0.9),  # Volteo horizontal con probabilidad del 90%\n        iaa.Sometimes(0.7, iaa.GaussianBlur(sigma=(0, 2.0))),  # Aplicar desenfoque gaussiano con probabilidad del 70%\n        iaa.Sometimes(0.6, iaa.AdditiveGaussianNoise(scale=(0, 0.05 * 255))),  # Agregar ruido gaussiano con probabilidad del 60%\n        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),  # Ajustar el contraste\n    ])\n    \n    # Aplica las transformaciones\n    augmented_img = seq(image=img)\n    return augmented_img\n\n# Selecciona las imágenes de edades entre 5 a 20 años y de 40 a 90 años\nselected_images = df[(df['age'] >= 5) & (df['age'] <= 20) | (df['age'] >= 40) & (df['age'] <= 90)]\n\n# Aplica aumentos de datos a las imágenes seleccionadas\naugmented_images = []\nfor image_path in selected_images['image_path']:\n    augmented_img = apply_data_augmentation(image_path)\n    augmented_images.append(augmented_img)\n\n# Crear una nueva lista de rutas de imagen para las imágenes aumentadas\naugmented_image_paths = []\n\n# Crear una nueva lista de edades y géneros para las imágenes aumentadas\naugmented_age_labels = []\naugmented_gender_labels = []\n\n# Directorio donde guardar las imágenes aumentadas\n\n############\noutput_directory = '/kaggle/working/augmented_images'  ##### Cambia esto a la ubicación deseada\nos.makedirs(output_directory, exist_ok=True)\n############\n\n# Iterar a través de las imágenes originales y sus correspondientes imágenes aumentadas\nfor image_path, age_label, gender_label, augmented_img in zip(selected_images['image_path'], selected_images['age'], selected_images['gender'], augmented_images):\n    # Generar una nueva ruta de imagen para la imagen aumentada\n    augmented_image_filename = os.path.basename(image_path).replace('.jpg', '_augmented.jpg')\n    augmented_image_path = os.path.join(output_directory, augmented_image_filename)\n    \n    # Guardar la ruta de imagen aumentada en la lista\n    augmented_image_paths.append(augmented_image_path)\n    \n    # Guardar la misma edad y género para la imagen aumentada\n    augmented_age_labels.append(age_label)\n    augmented_gender_labels.append(gender_label)\n    \n    # Guardar la imagen aumentada en el sistema de archivos\n    plt.imsave(augmented_image_path, augmented_img.astype(np.uint8))\n\n# Verifica el número total de imágenes originales y aumentadas\nprint(f\"Número de imágenes originales: {len(selected_images)}\")\nprint(f\"Número de imágenes aumentadas: {len(augmented_images)}\")\n\n# Crear un nuevo DataFrame con las imágenes aumentadas y sus etiquetas\naugmented_df = pd.DataFrame()\naugmented_df['image_path'] = augmented_image_paths\naugmented_df['age'] = augmented_age_labels\naugmented_df['gender'] = augmented_gender_labels","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:12:11.399379Z","iopub.execute_input":"2023-09-28T16:12:11.399715Z","iopub.status.idle":"2023-09-28T16:15:07.165611Z","shell.execute_reply.started":"2023-09-28T16:12:11.399686Z","shell.execute_reply":"2023-09-28T16:15:07.163728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df = pd.concat([df, augmented_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:20:28.158968Z","iopub.execute_input":"2023-09-28T16:20:28.159936Z","iopub.status.idle":"2023-09-28T16:20:28.165967Z","shell.execute_reply.started":"2023-09-28T16:20:28.159893Z","shell.execute_reply":"2023-09-28T16:20:28.164869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:20:28.698215Z","iopub.execute_input":"2023-09-28T16:20:28.698592Z","iopub.status.idle":"2023-09-28T16:20:28.712046Z","shell.execute_reply.started":"2023-09-28T16:20:28.698563Z","shell.execute_reply":"2023-09-28T16:20:28.710989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**BEFORE**","metadata":{}},{"cell_type":"code","source":"sns.distplot(df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:20:53.652825Z","iopub.execute_input":"2023-09-28T16:20:53.653777Z","iopub.status.idle":"2023-09-28T16:20:54.202142Z","shell.execute_reply.started":"2023-09-28T16:20:53.653742Z","shell.execute_reply":"2023-09-28T16:20:54.201156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AFTER**","metadata":{}},{"cell_type":"code","source":"sns.distplot(combined_df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:20:54.288437Z","iopub.execute_input":"2023-09-28T16:20:54.289098Z","iopub.status.idle":"2023-09-28T16:20:54.849551Z","shell.execute_reply.started":"2023-09-28T16:20:54.289063Z","shell.execute_reply":"2023-09-28T16:20:54.848500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualiza una imagen original y su versión aumentada\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.title(\"Imagen Original\")\nimg = load_img(selected_images.iloc[3]['image_path'])\nplt.imshow(img)\nplt.subplot(1, 2, 2)\nplt.title(\"Imagen Aumentada\")\naugmented_img = augmented_images[3]\naugmented_img = np.clip(augmented_img, 0, 255).astype(np.uint8)  # Normaliza los valores de píxeles\nplt.imshow(augmented_img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:20:54.894637Z","iopub.execute_input":"2023-09-28T16:20:54.894945Z","iopub.status.idle":"2023-09-28T16:20:55.399496Z","shell.execute_reply.started":"2023-09-28T16:20:54.894920Z","shell.execute_reply":"2023-09-28T16:20:55.398449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_image_features(images):\n    features = list()\n\n    for image in images:\n        img = load_img(image, grayscale=True)\n        img = img.resize((128, 128), Image.LANCZOS)\n        img = np.array(img)\n        features.append(img)\n\n    features = np.array(features)\n    features = features.reshape(len(features), 128, 128, 1)\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:21:15.413680Z","iopub.execute_input":"2023-09-28T16:21:15.414477Z","iopub.status.idle":"2023-09-28T16:21:15.421053Z","shell.execute_reply.started":"2023-09-28T16:21:15.414443Z","shell.execute_reply":"2023-09-28T16:21:15.419942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtra el DataFrame para obtener solo las imágenes con edad menor a 70\nfiltered_df = combined_df[combined_df['age'] < 70]\n\n# Extrae las características de las imágenes\nX = extract_image_features(filtered_df['image_path'])\n\n# Normaliza las características\nX = X / 255.0\n\n# Verifica la forma de X\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:33:10.385050Z","iopub.execute_input":"2023-09-28T16:33:10.385876Z","iopub.status.idle":"2023-09-28T16:35:50.329609Z","shell.execute_reply.started":"2023-09-28T16:33:10.385835Z","shell.execute_reply":"2023-09-28T16:35:50.328530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_gender = np.array(filtered_df['gender'])\ny_age = np.array(filtered_df['age'])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:35:50.331234Z","iopub.execute_input":"2023-09-28T16:35:50.331530Z","iopub.status.idle":"2023-09-28T16:35:50.336491Z","shell.execute_reply.started":"2023-09-28T16:35:50.331505Z","shell.execute_reply":"2023-09-28T16:35:50.335670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Duplica el canal de imágenes en escala de grises para convertirlas en imágenes RGB\nX_rgb = np.repeat(X, 3, axis=-1)\n\n# Asegúrate de que las imágenes estén en el rango [0, 255]\nX_rgb = X_rgb * 255\n\n# Redimensiona tus imágenes a 224x224\ndef resize_images(images):\n    resized_images = []\n    for image in images:\n        img = cv2.resize(image, (224, 224))\n        resized_images.append(img)\n    return np.array(resized_images)\n\nX_rgb = resize_images(X_rgb)\n\n# Asegúrate de que las imágenes estén en el rango [0, 1]\nX_rgb = X_rgb / 255.0\n\n# Divide tus datos en conjuntos de entrenamiento y prueba\nX_train, X_test, y_gender_train, y_gender_test, y_age_train, y_age_test = train_test_split(X_rgb, y_gender, y_age, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:35:50.337498Z","iopub.execute_input":"2023-09-28T16:35:50.337782Z","iopub.status.idle":"2023-09-28T16:37:17.654122Z","shell.execute_reply.started":"2023-09-28T16:35:50.337759Z","shell.execute_reply":"2023-09-28T16:37:17.652880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definir la entrada de la red\ninput_shape = (224, 224, 3)\n\nwith strategy.scope():\n    inputs = Input(shape=input_shape)\n\n    # Capas de convolución y max-pooling\n    conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n    max_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n    conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(max_1)\n    max_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n    conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu')(max_2)\n    max_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\n    conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu')(max_3)\n    max_4 = MaxPooling2D(pool_size=(2, 2))(conv_4)\n\n    # Capas de aplanamiento y completamente conectadas\n    flatten = Flatten()(max_4)\n    dense_1 = Dense(256, activation='relu')(flatten)\n    dropout_1 = Dropout(0.3)(dense_1)\n\n    # Capa de salida para la predicción de género\n    output_gender = Dense(1, activation='sigmoid', name='gender_out')(dropout_1)\n\n    # Crear el modelo\n    gender_model = Model(inputs=inputs, outputs=output_gender)\n\n    # Compilar el modelo solo para la predicción de género\n    gender_model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n\n    \n\n    inputs = Input(shape=input_shape)\n\n    # Convolution and max-pooling layers\n    conv_1 = Conv2D(64, kernel_size=(3, 3), activation='relu')(inputs)\n    max_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n    conv_2 = Conv2D(128, kernel_size=(3, 3), activation='relu')(max_1)\n    max_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n    conv_3 = Conv2D(256, kernel_size=(3, 3), activation='relu')(max_2)\n    max_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\n    conv_4 = Conv2D(512, kernel_size=(3, 3), activation='relu')(max_3)\n    max_4 = MaxPooling2D(pool_size=(2, 2))(conv_4)\n\n    # Flattening and fully connected layers\n    flatten = Flatten()(max_4)\n    dense_1 = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(flatten)\n    dropout_1 = Dropout(0.5)(dense_1)\n    dense_2 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(dropout_1)\n    dropout_2 = Dropout(0.3)(dense_2)\n    dense_3 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(dropout_2)\n    output_age = Dense(1, activation='linear', name='age_out')(dense_3)\n\n    # Create and compile the age model\n    age_model = Model(inputs=inputs, outputs=output_age)\n    age_model.compile(loss='mean_absolute_error', optimizer='RMSprop', metrics=['mae'])\n\n    # Entrena ambos modelos por separado\n    gender_model.fit(X_train, y_gender_train, epochs=20, batch_size=32, validation_split=0.2)\n    age_model.fit(X_train, y_age_train, epochs=20, batch_size=32, validation_split=0.2)\n\n    # Evalúa ambos modelos\n    gender_loss, gender_accuracy = gender_model.evaluate(X_test, y_gender_test)\n    age_loss, age_mae = age_model.evaluate(X_test, y_age_test)\n\nprint(\"Gender Model - Loss:\", gender_loss, \"Accuracy:\", gender_accuracy)\nprint(\"Age Model - Loss:\", age_loss, \"MAE:\", age_mae)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:15:45.367983Z","iopub.execute_input":"2023-09-28T18:15:45.369558Z","iopub.status.idle":"2023-09-28T18:30:55.095274Z","shell.execute_reply.started":"2023-09-28T18:15:45.369496Z","shell.execute_reply":"2023-09-28T18:30:55.093954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Carga una imagen de prueba\nimg_path = '/kaggle/input/imageess/cara5.jpg'  # Reemplaza con la ruta de tu propia imagen\nimg = image.load_img(img_path, target_size=(224, 224))\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)  # Añade una dimensión para el lote (batch)\n\n# Preprocesa la imagen\nimg_array /= 255.0  # Normaliza la imagen\n\n# Realiza la predicción de género\ngender_prediction = gender_model.predict(img_array)\n\n# Convierte la predicción de género en una etiqueta (Hombre o Mujer)\ngender_label = \"Hombre\" if gender_prediction < 0.5 else \"Mujer\"\n\n# Realiza la predicción de edad\nage_prediction = age_model.predict(img_array)\n\n# Muestra la imagen y las predicciones\nplt.imshow(img)\nplt.axis('off')\nplt.title(f'Género: {gender_label}, Edad: {int(age_prediction[0][0])} años')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:26:21.820700Z","iopub.execute_input":"2023-09-28T19:26:21.821125Z","iopub.status.idle":"2023-09-28T19:26:23.059919Z","shell.execute_reply.started":"2023-09-28T19:26:21.821093Z","shell.execute_reply":"2023-09-28T19:26:23.058593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}